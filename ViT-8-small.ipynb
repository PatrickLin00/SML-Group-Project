{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11fc1a87-fe13-4f04-a53f-de3889d3f9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dysx5\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa21c7a-24f3-4b9c-b40e-ff0257b424fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "image_size = 72\n",
    "num_heads = 4\n",
    "projection_dim = 64\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim\n",
    "]\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1048] \n",
    "\n",
    "num_classes = 10\n",
    "input_shape=(32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2057013-72e3-4792-aca7-b048c0c31f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation = tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d5030b-06f0-441a-acb5-2817650e67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images = images,\n",
    "            sizes = [1, self.patch_size, self.patch_size, 1],\n",
    "            strides = [1, self.patch_size, self.patch_size, 1],\n",
    "            rates = [1, 1, 1, 1],\n",
    "            padding = \"VALID\", \n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e4f4065-2a4c-44c8-b944-075c4104a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units = projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim = num_patches, output_dim = projection_dim\n",
    "        )\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start = 0, limit = self.num_patches, delta = 1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb083e4-fe1d-4e4e-995a-d0543e3cbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier(input_patch_size, input_data_augmentation):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    #augmented data\n",
    "    augmented = input_data_augmentation(inputs)\n",
    "    #create patches\n",
    "    patches = Patches(input_patch_size)(augmented)\n",
    "    # encode patches\n",
    "    num_patches = (image_size // input_patch_size) ** 2\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer Block\n",
    "    for _ in range(transformer_layers):\n",
    "        # layer normalisation\n",
    "        x1 = layers.LayerNormalization(epsilon= 1e-6)(encoded_patches)\n",
    "        # Create a multi -  head attention layer\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads = num_heads,\n",
    "            key_dim = projection_dim,\n",
    "            dropout = 0\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        #layer normalisation\n",
    "        x3 = layers.LayerNormalization(epsilon = 1e-6)(x2)\n",
    "        # MLP\n",
    "        x2 = mlp(x3, hidden_units = transformer_units, dropout_rate = 0)\n",
    "        # skip connection2\n",
    "        encoded_patches =  layers.Add()([x3, x2])\n",
    "    # Create a [batch_size, projection_dim] tensor\n",
    "    representation = layers.LayerNormalization(epsilon = 1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0)(representation)\n",
    "\n",
    "    # Add MLP \n",
    "    features = mlp(representation, hidden_units = mlp_head_units, dropout_rate = 0)\n",
    "    #classify ouputs\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras Model\n",
    "    model = keras.Model(inputs = inputs, outputs = logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6a52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ViT_model(input_patch_size, input_data_augmentation):\n",
    "    \n",
    "    model = create_vit_classifier(input_patch_size, input_data_augmentation)\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53a97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_dataset(dir):\n",
    "    train_npy = np.load(dir)[:6000]\n",
    "    label_npy = np.load('train_labels.npy')\n",
    "\n",
    "    return train_npy, label_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2488ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size_configs = [12, 18, 24]\n",
    "\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list  = []\n",
    "test_precision_list  = []\n",
    "test_recall_list  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb4d7eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGIN = 'origin_cifar10.npy'\n",
    "SMALL = 'small_noise_cifar10.npy'\n",
    "MEDIUM = 'medium_noise_cifar10.npy'\n",
    "LARGE = 'large_noise_cifar10.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "908f31c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_k_1 1\n",
      "patch_size: 12\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 16s 504ms/step - loss: 2.6119 - accuracy: 0.2415 - val_loss: 1.8780 - val_accuracy: 0.3233\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 10s 447ms/step - loss: 1.6531 - accuracy: 0.4241 - val_loss: 1.7822 - val_accuracy: 0.3567\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 1.2584 - accuracy: 0.5585 - val_loss: 1.6708 - val_accuracy: 0.4233\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.7456 - accuracy: 0.7544 - val_loss: 1.8838 - val_accuracy: 0.4000\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 10s 455ms/step - loss: 0.4280 - accuracy: 0.8656 - val_loss: 2.0274 - val_accuracy: 0.4367\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 16s 505ms/step - loss: 2.5011 - accuracy: 0.2485 - val_loss: 1.9754 - val_accuracy: 0.2900\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 11s 482ms/step - loss: 1.7020 - accuracy: 0.4089 - val_loss: 1.7636 - val_accuracy: 0.3900\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 11s 479ms/step - loss: 1.3197 - accuracy: 0.5304 - val_loss: 1.7296 - val_accuracy: 0.4033\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.8441 - accuracy: 0.7185 - val_loss: 1.9307 - val_accuracy: 0.4067\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 11s 492ms/step - loss: 0.5178 - accuracy: 0.8485 - val_loss: 1.8833 - val_accuracy: 0.4400\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 16s 511ms/step - loss: 2.6166 - accuracy: 0.2478 - val_loss: 2.0184 - val_accuracy: 0.3300\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 11s 489ms/step - loss: 1.6783 - accuracy: 0.4067 - val_loss: 1.8023 - val_accuracy: 0.3633\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 11s 485ms/step - loss: 1.2552 - accuracy: 0.5585 - val_loss: 1.9344 - val_accuracy: 0.3500\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 10s 476ms/step - loss: 0.8485 - accuracy: 0.7219 - val_loss: 1.8646 - val_accuracy: 0.3600\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 10s 478ms/step - loss: 0.4617 - accuracy: 0.8596 - val_loss: 2.0686 - val_accuracy: 0.4100\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 17s 538ms/step - loss: 2.5112 - accuracy: 0.2581 - val_loss: 1.9587 - val_accuracy: 0.3033\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 11s 486ms/step - loss: 1.6253 - accuracy: 0.4193 - val_loss: 1.8405 - val_accuracy: 0.3600\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 11s 505ms/step - loss: 1.2154 - accuracy: 0.5756 - val_loss: 1.9294 - val_accuracy: 0.3767\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 11s 510ms/step - loss: 0.7727 - accuracy: 0.7504 - val_loss: 1.8904 - val_accuracy: 0.4167\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 0.4174 - accuracy: 0.8733 - val_loss: 2.2023 - val_accuracy: 0.3967\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 17s 540ms/step - loss: 2.6835 - accuracy: 0.2344 - val_loss: 1.9940 - val_accuracy: 0.2967\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 12s 531ms/step - loss: 1.7462 - accuracy: 0.3752 - val_loss: 1.7333 - val_accuracy: 0.3733\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 12s 528ms/step - loss: 1.4254 - accuracy: 0.5033 - val_loss: 1.6525 - val_accuracy: 0.4333\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 1.0048 - accuracy: 0.6556 - val_loss: 1.6772 - val_accuracy: 0.4567\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 11s 501ms/step - loss: 0.5839 - accuracy: 0.8133 - val_loss: 1.8487 - val_accuracy: 0.4233\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 18s 558ms/step - loss: 2.4932 - accuracy: 0.2396 - val_loss: 2.0530 - val_accuracy: 0.2900\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 1.7072 - accuracy: 0.3870 - val_loss: 1.7946 - val_accuracy: 0.3733\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 11s 522ms/step - loss: 1.2949 - accuracy: 0.5511 - val_loss: 1.7428 - val_accuracy: 0.3767\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 11s 509ms/step - loss: 0.8007 - accuracy: 0.7407 - val_loss: 2.0541 - val_accuracy: 0.3333\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 12s 529ms/step - loss: 0.5711 - accuracy: 0.8167 - val_loss: 2.2348 - val_accuracy: 0.3767\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 18s 566ms/step - loss: 2.7277 - accuracy: 0.2348 - val_loss: 1.9671 - val_accuracy: 0.3300\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 12s 536ms/step - loss: 1.6245 - accuracy: 0.4304 - val_loss: 1.8136 - val_accuracy: 0.3500\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 11s 522ms/step - loss: 1.2206 - accuracy: 0.5826 - val_loss: 1.7568 - val_accuracy: 0.4500\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 12s 532ms/step - loss: 0.7541 - accuracy: 0.7433 - val_loss: 1.8894 - val_accuracy: 0.4467\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 12s 537ms/step - loss: 0.4060 - accuracy: 0.8700 - val_loss: 2.0609 - val_accuracy: 0.4167\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 17s 550ms/step - loss: 2.5201 - accuracy: 0.2574 - val_loss: 1.9641 - val_accuracy: 0.3100\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 1.6554 - accuracy: 0.4181 - val_loss: 1.7214 - val_accuracy: 0.4100\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 12s 529ms/step - loss: 1.2549 - accuracy: 0.5607 - val_loss: 1.6673 - val_accuracy: 0.4433\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 0.8032 - accuracy: 0.7344 - val_loss: 1.9546 - val_accuracy: 0.3833\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 0.5071 - accuracy: 0.8422 - val_loss: 1.9618 - val_accuracy: 0.4400\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 18s 578ms/step - loss: 2.3548 - accuracy: 0.2630 - val_loss: 1.9046 - val_accuracy: 0.3133\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 11s 523ms/step - loss: 1.5722 - accuracy: 0.4467 - val_loss: 1.8220 - val_accuracy: 0.3533\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 12s 524ms/step - loss: 1.0822 - accuracy: 0.6393 - val_loss: 1.7787 - val_accuracy: 0.4467\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 12s 538ms/step - loss: 0.5810 - accuracy: 0.8141 - val_loss: 1.9099 - val_accuracy: 0.4167\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 0.2649 - accuracy: 0.9233 - val_loss: 2.2804 - val_accuracy: 0.4200\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 18s 581ms/step - loss: 2.4787 - accuracy: 0.2437 - val_loss: 1.9110 - val_accuracy: 0.3400\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 11s 524ms/step - loss: 1.6557 - accuracy: 0.4078 - val_loss: 1.6402 - val_accuracy: 0.4233\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 11s 498ms/step - loss: 1.2084 - accuracy: 0.5715 - val_loss: 1.7168 - val_accuracy: 0.4300\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 11s 506ms/step - loss: 0.7369 - accuracy: 0.7537 - val_loss: 1.9362 - val_accuracy: 0.4100\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 11s 504ms/step - loss: 0.3977 - accuracy: 0.8796 - val_loss: 2.2484 - val_accuracy: 0.4300\n",
      "mean_score: 0.4189999997615814 ( patch_size 12 )\n",
      "patch_size: 18\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 10s 249ms/step - loss: 2.1731 - accuracy: 0.2907 - val_loss: 1.8388 - val_accuracy: 0.3333\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 210ms/step - loss: 1.5261 - accuracy: 0.4637 - val_loss: 1.7104 - val_accuracy: 0.4267\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 209ms/step - loss: 1.1439 - accuracy: 0.5959 - val_loss: 1.7595 - val_accuracy: 0.4200\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.7872 - accuracy: 0.7304 - val_loss: 1.9619 - val_accuracy: 0.3967\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 206ms/step - loss: 0.4778 - accuracy: 0.8470 - val_loss: 2.1702 - val_accuracy: 0.4133\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 10s 237ms/step - loss: 2.1773 - accuracy: 0.2678 - val_loss: 1.8624 - val_accuracy: 0.3200\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 218ms/step - loss: 1.5301 - accuracy: 0.4637 - val_loss: 1.7128 - val_accuracy: 0.4100\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 210ms/step - loss: 1.1587 - accuracy: 0.5904 - val_loss: 1.9154 - val_accuracy: 0.3633\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 209ms/step - loss: 0.7609 - accuracy: 0.7470 - val_loss: 1.7302 - val_accuracy: 0.4433\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 213ms/step - loss: 0.4595 - accuracy: 0.8500 - val_loss: 2.0800 - val_accuracy: 0.4433\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 10s 246ms/step - loss: 2.2652 - accuracy: 0.2619 - val_loss: 1.9738 - val_accuracy: 0.3233\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 221ms/step - loss: 1.6381 - accuracy: 0.4115 - val_loss: 1.8442 - val_accuracy: 0.3833\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 231ms/step - loss: 1.2566 - accuracy: 0.5652 - val_loss: 1.7650 - val_accuracy: 0.3967\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 220ms/step - loss: 0.8096 - accuracy: 0.7233 - val_loss: 1.9183 - val_accuracy: 0.4233\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 219ms/step - loss: 0.4916 - accuracy: 0.8378 - val_loss: 2.0216 - val_accuracy: 0.3800\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 10s 241ms/step - loss: 2.1824 - accuracy: 0.2811 - val_loss: 1.9839 - val_accuracy: 0.3133\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 218ms/step - loss: 1.5472 - accuracy: 0.4452 - val_loss: 1.7298 - val_accuracy: 0.3933\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 223ms/step - loss: 1.1099 - accuracy: 0.6030 - val_loss: 1.8976 - val_accuracy: 0.3233\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 220ms/step - loss: 0.6935 - accuracy: 0.7678 - val_loss: 1.9932 - val_accuracy: 0.4133\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 218ms/step - loss: 0.4375 - accuracy: 0.8585 - val_loss: 2.2346 - val_accuracy: 0.4100\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 11s 267ms/step - loss: 2.2872 - accuracy: 0.2581 - val_loss: 1.7379 - val_accuracy: 0.3667\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 232ms/step - loss: 1.5699 - accuracy: 0.4448 - val_loss: 1.6734 - val_accuracy: 0.3933\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 1.1662 - accuracy: 0.5833 - val_loss: 1.6513 - val_accuracy: 0.4433\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 218ms/step - loss: 0.8283 - accuracy: 0.7185 - val_loss: 1.7142 - val_accuracy: 0.4533\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 222ms/step - loss: 0.5204 - accuracy: 0.8222 - val_loss: 1.8254 - val_accuracy: 0.4467\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 11s 254ms/step - loss: 2.2265 - accuracy: 0.2741 - val_loss: 1.8760 - val_accuracy: 0.3367\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 228ms/step - loss: 1.5544 - accuracy: 0.4485 - val_loss: 1.8903 - val_accuracy: 0.3900\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 232ms/step - loss: 1.1355 - accuracy: 0.6033 - val_loss: 1.9529 - val_accuracy: 0.3567\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 222ms/step - loss: 0.8235 - accuracy: 0.7193 - val_loss: 2.0354 - val_accuracy: 0.3567\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 227ms/step - loss: 0.4950 - accuracy: 0.8407 - val_loss: 2.1398 - val_accuracy: 0.4033\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 11s 249ms/step - loss: 2.1755 - accuracy: 0.2793 - val_loss: 1.9377 - val_accuracy: 0.2833\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 212ms/step - loss: 1.5037 - accuracy: 0.4633 - val_loss: 2.0011 - val_accuracy: 0.3700\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 225ms/step - loss: 1.0984 - accuracy: 0.6056 - val_loss: 1.8344 - val_accuracy: 0.3933\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 215ms/step - loss: 0.7327 - accuracy: 0.7485 - val_loss: 1.8219 - val_accuracy: 0.4233\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 232ms/step - loss: 0.4120 - accuracy: 0.8704 - val_loss: 2.0552 - val_accuracy: 0.4267\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 11s 261ms/step - loss: 2.2379 - accuracy: 0.2589 - val_loss: 2.1404 - val_accuracy: 0.2933\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 221ms/step - loss: 1.6211 - accuracy: 0.4285 - val_loss: 1.8222 - val_accuracy: 0.3667\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 239ms/step - loss: 1.2059 - accuracy: 0.5774 - val_loss: 1.7471 - val_accuracy: 0.3667\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 230ms/step - loss: 0.8377 - accuracy: 0.7115 - val_loss: 1.7893 - val_accuracy: 0.4033\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 231ms/step - loss: 0.5061 - accuracy: 0.8359 - val_loss: 2.1079 - val_accuracy: 0.3967\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 11s 280ms/step - loss: 2.3273 - accuracy: 0.2578 - val_loss: 1.8768 - val_accuracy: 0.3533\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 236ms/step - loss: 1.6110 - accuracy: 0.4230 - val_loss: 1.6536 - val_accuracy: 0.4100\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 242ms/step - loss: 1.2264 - accuracy: 0.5648 - val_loss: 1.6978 - val_accuracy: 0.4367\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 237ms/step - loss: 0.8459 - accuracy: 0.7089 - val_loss: 1.7729 - val_accuracy: 0.4433\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 232ms/step - loss: 0.4835 - accuracy: 0.8448 - val_loss: 1.8753 - val_accuracy: 0.4433\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 12s 280ms/step - loss: 2.1934 - accuracy: 0.2744 - val_loss: 1.8157 - val_accuracy: 0.3400\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 239ms/step - loss: 1.4643 - accuracy: 0.4733 - val_loss: 1.6506 - val_accuracy: 0.3833\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 247ms/step - loss: 1.0330 - accuracy: 0.6515 - val_loss: 1.7615 - val_accuracy: 0.4033\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 247ms/step - loss: 0.6954 - accuracy: 0.7637 - val_loss: 1.8712 - val_accuracy: 0.4167\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 243ms/step - loss: 0.4118 - accuracy: 0.8748 - val_loss: 2.2827 - val_accuracy: 0.3867\n",
      "mean_score: 0.4149999976158142 ( patch_size 18 )\n",
      "patch_size: 24\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 10s 205ms/step - loss: 2.1632 - accuracy: 0.2733 - val_loss: 1.9225 - val_accuracy: 0.3100\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 1.6020 - accuracy: 0.4222 - val_loss: 1.8308 - val_accuracy: 0.3600\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 1.2817 - accuracy: 0.5556 - val_loss: 1.8617 - val_accuracy: 0.4133\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 166ms/step - loss: 0.9960 - accuracy: 0.6493 - val_loss: 1.8931 - val_accuracy: 0.4033\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.6653 - accuracy: 0.7822 - val_loss: 2.1958 - val_accuracy: 0.4033\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 10s 218ms/step - loss: 2.1706 - accuracy: 0.2704 - val_loss: 1.8971 - val_accuracy: 0.3133\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 176ms/step - loss: 1.6473 - accuracy: 0.4093 - val_loss: 1.7610 - val_accuracy: 0.3867\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 1.3219 - accuracy: 0.5415 - val_loss: 1.7072 - val_accuracy: 0.3667\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 169ms/step - loss: 1.0452 - accuracy: 0.6311 - val_loss: 1.8398 - val_accuracy: 0.4300\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 182ms/step - loss: 0.7522 - accuracy: 0.7422 - val_loss: 1.8225 - val_accuracy: 0.3867\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 10s 213ms/step - loss: 2.2099 - accuracy: 0.2515 - val_loss: 1.9656 - val_accuracy: 0.2933\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 186ms/step - loss: 1.6675 - accuracy: 0.4000 - val_loss: 1.9569 - val_accuracy: 0.3267\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 177ms/step - loss: 1.3951 - accuracy: 0.4919 - val_loss: 1.8212 - val_accuracy: 0.3733\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 178ms/step - loss: 1.0712 - accuracy: 0.6185 - val_loss: 1.7486 - val_accuracy: 0.4100\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 178ms/step - loss: 0.7865 - accuracy: 0.7322 - val_loss: 1.8479 - val_accuracy: 0.3933\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 10s 211ms/step - loss: 2.2259 - accuracy: 0.2519 - val_loss: 1.9646 - val_accuracy: 0.3167\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 181ms/step - loss: 1.6757 - accuracy: 0.4022 - val_loss: 1.8305 - val_accuracy: 0.3533\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 178ms/step - loss: 1.4180 - accuracy: 0.4919 - val_loss: 1.8150 - val_accuracy: 0.3833\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 195ms/step - loss: 1.0581 - accuracy: 0.6367 - val_loss: 2.0548 - val_accuracy: 0.3433\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 177ms/step - loss: 0.8381 - accuracy: 0.7100 - val_loss: 2.0613 - val_accuracy: 0.3600\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 12s 247ms/step - loss: 2.1889 - accuracy: 0.2530 - val_loss: 1.9600 - val_accuracy: 0.3000\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 190ms/step - loss: 1.7226 - accuracy: 0.3978 - val_loss: 1.6983 - val_accuracy: 0.3967\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 183ms/step - loss: 1.4298 - accuracy: 0.4963 - val_loss: 1.6577 - val_accuracy: 0.4300\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 200ms/step - loss: 1.0717 - accuracy: 0.6185 - val_loss: 1.8097 - val_accuracy: 0.4067\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 185ms/step - loss: 0.7974 - accuracy: 0.7311 - val_loss: 1.8311 - val_accuracy: 0.4400\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 10s 240ms/step - loss: 2.1816 - accuracy: 0.2615 - val_loss: 2.0379 - val_accuracy: 0.3200\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 201ms/step - loss: 1.6463 - accuracy: 0.4204 - val_loss: 1.9180 - val_accuracy: 0.3433\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 201ms/step - loss: 1.3632 - accuracy: 0.5215 - val_loss: 1.7558 - val_accuracy: 0.4267\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 223ms/step - loss: 1.0246 - accuracy: 0.6422 - val_loss: 2.0103 - val_accuracy: 0.3500\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 239ms/step - loss: 0.8510 - accuracy: 0.6930 - val_loss: 2.1074 - val_accuracy: 0.3800\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 11s 267ms/step - loss: 2.1384 - accuracy: 0.2711 - val_loss: 2.0846 - val_accuracy: 0.2800\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 231ms/step - loss: 1.6097 - accuracy: 0.4337 - val_loss: 1.9029 - val_accuracy: 0.3500\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 240ms/step - loss: 1.2870 - accuracy: 0.5522 - val_loss: 1.8086 - val_accuracy: 0.3633\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 242ms/step - loss: 0.9669 - accuracy: 0.6607 - val_loss: 1.9043 - val_accuracy: 0.3800\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 240ms/step - loss: 0.7183 - accuracy: 0.7474 - val_loss: 2.2408 - val_accuracy: 0.4033\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 11s 265ms/step - loss: 2.1590 - accuracy: 0.2619 - val_loss: 1.8789 - val_accuracy: 0.3267\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 229ms/step - loss: 1.6254 - accuracy: 0.4326 - val_loss: 1.6881 - val_accuracy: 0.3800\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 217ms/step - loss: 1.3120 - accuracy: 0.5404 - val_loss: 1.8814 - val_accuracy: 0.3600\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 229ms/step - loss: 0.9555 - accuracy: 0.6681 - val_loss: 2.0022 - val_accuracy: 0.3967\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 231ms/step - loss: 0.6812 - accuracy: 0.7611 - val_loss: 2.0436 - val_accuracy: 0.3833\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 12s 300ms/step - loss: 2.1531 - accuracy: 0.2659 - val_loss: 1.8955 - val_accuracy: 0.3067\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 6s 260ms/step - loss: 1.6505 - accuracy: 0.4104 - val_loss: 1.7715 - val_accuracy: 0.4067\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 264ms/step - loss: 1.3343 - accuracy: 0.5300 - val_loss: 1.7723 - val_accuracy: 0.3900\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 258ms/step - loss: 1.0098 - accuracy: 0.6433 - val_loss: 1.6429 - val_accuracy: 0.4200\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 246ms/step - loss: 0.6938 - accuracy: 0.7767 - val_loss: 1.9976 - val_accuracy: 0.4133\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 11s 280ms/step - loss: 2.1919 - accuracy: 0.2637 - val_loss: 1.8190 - val_accuracy: 0.3400\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 1.6633 - accuracy: 0.4122 - val_loss: 1.8134 - val_accuracy: 0.3467\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 235ms/step - loss: 1.4209 - accuracy: 0.5048 - val_loss: 1.6595 - val_accuracy: 0.3867\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 242ms/step - loss: 1.0693 - accuracy: 0.6263 - val_loss: 1.7878 - val_accuracy: 0.4233\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 242ms/step - loss: 0.7730 - accuracy: 0.7441 - val_loss: 1.9170 - val_accuracy: 0.3900\n",
      "mean_score: 0.395333331823349 ( patch_size 24 )\n",
      "94/94 [==============================] - 11s 113ms/step - loss: 2.1280 - accuracy: 0.4233\n",
      "index_k_1 2\n",
      "patch_size: 12\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 24s 852ms/step - loss: 2.5933 - accuracy: 0.2393 - val_loss: 1.9527 - val_accuracy: 0.2767\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 18s 804ms/step - loss: 1.7048 - accuracy: 0.4019 - val_loss: 1.8217 - val_accuracy: 0.3533\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 18s 825ms/step - loss: 1.3053 - accuracy: 0.5326 - val_loss: 1.9390 - val_accuracy: 0.3233\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 17s 781ms/step - loss: 0.9305 - accuracy: 0.6856 - val_loss: 2.0078 - val_accuracy: 0.3433\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 17s 762ms/step - loss: 0.4767 - accuracy: 0.8519 - val_loss: 2.1797 - val_accuracy: 0.3767\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 23s 793ms/step - loss: 2.6395 - accuracy: 0.2363 - val_loss: 1.9768 - val_accuracy: 0.3100\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 16s 749ms/step - loss: 1.7431 - accuracy: 0.3800 - val_loss: 1.8139 - val_accuracy: 0.3567\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 16s 744ms/step - loss: 1.3265 - accuracy: 0.5370 - val_loss: 1.6297 - val_accuracy: 0.4133\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 16s 734ms/step - loss: 0.8301 - accuracy: 0.7315 - val_loss: 1.6709 - val_accuracy: 0.4333\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 16s 740ms/step - loss: 0.4509 - accuracy: 0.8567 - val_loss: 1.9795 - val_accuracy: 0.3700\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 23s 853ms/step - loss: 2.4387 - accuracy: 0.2719 - val_loss: 1.8469 - val_accuracy: 0.3033\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 18s 797ms/step - loss: 1.5606 - accuracy: 0.4589 - val_loss: 1.7397 - val_accuracy: 0.3700\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 18s 797ms/step - loss: 1.0977 - accuracy: 0.6163 - val_loss: 1.8631 - val_accuracy: 0.3733\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 18s 795ms/step - loss: 0.5974 - accuracy: 0.8159 - val_loss: 1.9146 - val_accuracy: 0.3867\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 17s 794ms/step - loss: 0.3537 - accuracy: 0.8893 - val_loss: 2.0387 - val_accuracy: 0.4333\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 24s 840ms/step - loss: 2.5194 - accuracy: 0.2474 - val_loss: 2.0259 - val_accuracy: 0.2800\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 17s 776ms/step - loss: 1.6647 - accuracy: 0.3948 - val_loss: 1.7199 - val_accuracy: 0.3667\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 18s 839ms/step - loss: 1.2025 - accuracy: 0.5726 - val_loss: 1.7555 - val_accuracy: 0.3567\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 18s 832ms/step - loss: 0.7215 - accuracy: 0.7581 - val_loss: 1.8869 - val_accuracy: 0.3933\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 18s 799ms/step - loss: 0.4109 - accuracy: 0.8778 - val_loss: 2.1416 - val_accuracy: 0.3800\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 23s 855ms/step - loss: 2.4626 - accuracy: 0.2459 - val_loss: 2.1284 - val_accuracy: 0.2800\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 18s 830ms/step - loss: 1.6893 - accuracy: 0.3974 - val_loss: 1.8026 - val_accuracy: 0.3800\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 19s 848ms/step - loss: 1.2581 - accuracy: 0.5670 - val_loss: 1.7772 - val_accuracy: 0.3667\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 18s 822ms/step - loss: 0.8102 - accuracy: 0.7270 - val_loss: 1.8627 - val_accuracy: 0.4067\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 18s 840ms/step - loss: 0.4293 - accuracy: 0.8678 - val_loss: 2.0565 - val_accuracy: 0.4033\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 24s 863ms/step - loss: 2.7126 - accuracy: 0.2341 - val_loss: 2.0497 - val_accuracy: 0.2767\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 18s 835ms/step - loss: 1.7558 - accuracy: 0.3722 - val_loss: 1.8524 - val_accuracy: 0.3600\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 19s 846ms/step - loss: 1.4178 - accuracy: 0.4948 - val_loss: 1.6690 - val_accuracy: 0.4100\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 19s 854ms/step - loss: 1.0569 - accuracy: 0.6456 - val_loss: 1.8413 - val_accuracy: 0.4233\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 19s 853ms/step - loss: 0.7162 - accuracy: 0.7707 - val_loss: 2.0871 - val_accuracy: 0.4233\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 24s 831ms/step - loss: 2.5341 - accuracy: 0.2296 - val_loss: 1.9512 - val_accuracy: 0.2800\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 17s 797ms/step - loss: 1.6280 - accuracy: 0.4222 - val_loss: 1.9536 - val_accuracy: 0.3400\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 18s 796ms/step - loss: 1.1990 - accuracy: 0.5748 - val_loss: 1.9692 - val_accuracy: 0.3300\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 17s 782ms/step - loss: 0.7431 - accuracy: 0.7578 - val_loss: 2.2413 - val_accuracy: 0.3500\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 18s 808ms/step - loss: 0.3494 - accuracy: 0.9026 - val_loss: 2.4552 - val_accuracy: 0.3533\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 24s 845ms/step - loss: 2.4517 - accuracy: 0.2270 - val_loss: 1.8810 - val_accuracy: 0.3433\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 18s 822ms/step - loss: 1.6786 - accuracy: 0.4033 - val_loss: 1.6161 - val_accuracy: 0.4400\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 18s 824ms/step - loss: 1.2694 - accuracy: 0.5533 - val_loss: 1.6340 - val_accuracy: 0.4267\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 18s 821ms/step - loss: 0.8569 - accuracy: 0.7115 - val_loss: 1.7123 - val_accuracy: 0.4500\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 18s 811ms/step - loss: 0.4954 - accuracy: 0.8459 - val_loss: 1.8625 - val_accuracy: 0.4100\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 24s 863ms/step - loss: 2.5255 - accuracy: 0.2500 - val_loss: 1.8967 - val_accuracy: 0.2933\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 18s 816ms/step - loss: 1.5943 - accuracy: 0.4385 - val_loss: 1.7882 - val_accuracy: 0.3533\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 18s 801ms/step - loss: 1.0910 - accuracy: 0.6267 - val_loss: 1.8255 - val_accuracy: 0.3667\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 18s 805ms/step - loss: 0.6895 - accuracy: 0.7722 - val_loss: 2.0017 - val_accuracy: 0.3767\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 18s 796ms/step - loss: 0.3125 - accuracy: 0.9122 - val_loss: 2.1940 - val_accuracy: 0.4133\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 24s 852ms/step - loss: 2.5373 - accuracy: 0.2400 - val_loss: 2.3796 - val_accuracy: 0.2467\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 18s 822ms/step - loss: 1.7060 - accuracy: 0.3911 - val_loss: 1.9731 - val_accuracy: 0.3767\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 18s 819ms/step - loss: 1.2847 - accuracy: 0.5519 - val_loss: 1.8442 - val_accuracy: 0.4100\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 18s 835ms/step - loss: 0.7950 - accuracy: 0.7430 - val_loss: 1.8520 - val_accuracy: 0.4500\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 18s 836ms/step - loss: 0.3817 - accuracy: 0.8878 - val_loss: 2.0970 - val_accuracy: 0.4000\n",
      "mean_score: 0.39633333384990693 ( patch_size 12 )\n",
      "patch_size: 18\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 13s 383ms/step - loss: 2.2292 - accuracy: 0.2652 - val_loss: 1.9329 - val_accuracy: 0.3033\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 8s 349ms/step - loss: 1.5301 - accuracy: 0.4585 - val_loss: 1.8972 - val_accuracy: 0.3767\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 8s 342ms/step - loss: 1.1210 - accuracy: 0.6044 - val_loss: 1.9887 - val_accuracy: 0.3667\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 8s 350ms/step - loss: 0.7354 - accuracy: 0.7678 - val_loss: 2.2155 - val_accuracy: 0.3800\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 8s 346ms/step - loss: 0.4027 - accuracy: 0.8711 - val_loss: 2.3475 - val_accuracy: 0.3800\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 13s 367ms/step - loss: 2.2903 - accuracy: 0.2552 - val_loss: 1.8337 - val_accuracy: 0.3400\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 8s 342ms/step - loss: 1.6288 - accuracy: 0.4207 - val_loss: 1.6223 - val_accuracy: 0.4167\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 7s 331ms/step - loss: 1.2690 - accuracy: 0.5485 - val_loss: 1.7425 - val_accuracy: 0.4200\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 7s 337ms/step - loss: 0.8877 - accuracy: 0.6952 - val_loss: 1.7455 - val_accuracy: 0.4367\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 7s 330ms/step - loss: 0.4935 - accuracy: 0.8489 - val_loss: 1.8768 - val_accuracy: 0.4533\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 14s 374ms/step - loss: 2.2706 - accuracy: 0.2500 - val_loss: 1.9648 - val_accuracy: 0.2700\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 7s 330ms/step - loss: 1.6294 - accuracy: 0.4274 - val_loss: 1.8325 - val_accuracy: 0.3433\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 7s 340ms/step - loss: 1.2495 - accuracy: 0.5767 - val_loss: 1.8164 - val_accuracy: 0.3967\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 7s 332ms/step - loss: 0.8304 - accuracy: 0.7170 - val_loss: 1.9741 - val_accuracy: 0.3967\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 7s 336ms/step - loss: 0.4269 - accuracy: 0.8596 - val_loss: 2.1346 - val_accuracy: 0.3767\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 13s 379ms/step - loss: 2.1869 - accuracy: 0.2622 - val_loss: 1.8488 - val_accuracy: 0.3633\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 7s 332ms/step - loss: 1.5793 - accuracy: 0.4604 - val_loss: 1.8292 - val_accuracy: 0.3433\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 8s 352ms/step - loss: 1.2307 - accuracy: 0.5693 - val_loss: 1.7831 - val_accuracy: 0.3733\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 7s 329ms/step - loss: 0.8253 - accuracy: 0.7337 - val_loss: 1.6882 - val_accuracy: 0.4533\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 7s 329ms/step - loss: 0.4727 - accuracy: 0.8393 - val_loss: 2.0774 - val_accuracy: 0.3767\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 13s 365ms/step - loss: 2.2787 - accuracy: 0.2515 - val_loss: 1.9805 - val_accuracy: 0.2867\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 7s 331ms/step - loss: 1.6363 - accuracy: 0.4081 - val_loss: 1.8221 - val_accuracy: 0.3500\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 7s 332ms/step - loss: 1.2506 - accuracy: 0.5656 - val_loss: 1.7598 - val_accuracy: 0.3533\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 8s 343ms/step - loss: 0.8212 - accuracy: 0.7189 - val_loss: 1.9726 - val_accuracy: 0.3667\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 8s 353ms/step - loss: 0.4410 - accuracy: 0.8693 - val_loss: 2.2695 - val_accuracy: 0.3933\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 14s 397ms/step - loss: 2.2173 - accuracy: 0.2719 - val_loss: 1.7748 - val_accuracy: 0.3733\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 8s 345ms/step - loss: 1.5480 - accuracy: 0.4470 - val_loss: 1.7065 - val_accuracy: 0.4333\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 8s 352ms/step - loss: 1.1139 - accuracy: 0.6122 - val_loss: 1.7902 - val_accuracy: 0.3867\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 8s 349ms/step - loss: 0.7142 - accuracy: 0.7626 - val_loss: 1.8876 - val_accuracy: 0.4267\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 8s 343ms/step - loss: 0.3973 - accuracy: 0.8744 - val_loss: 2.0168 - val_accuracy: 0.4433\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 14s 378ms/step - loss: 2.1916 - accuracy: 0.2622 - val_loss: 1.8704 - val_accuracy: 0.2900\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 8s 347ms/step - loss: 1.5917 - accuracy: 0.4352 - val_loss: 1.9826 - val_accuracy: 0.2933\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 7s 338ms/step - loss: 1.2709 - accuracy: 0.5707 - val_loss: 2.0200 - val_accuracy: 0.3600\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 7s 340ms/step - loss: 0.8664 - accuracy: 0.7089 - val_loss: 2.0511 - val_accuracy: 0.3500\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 7s 341ms/step - loss: 0.4999 - accuracy: 0.8459 - val_loss: 2.4013 - val_accuracy: 0.3833\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 13s 383ms/step - loss: 2.2163 - accuracy: 0.2507 - val_loss: 1.8504 - val_accuracy: 0.3600\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 8s 348ms/step - loss: 1.6051 - accuracy: 0.4315 - val_loss: 1.6589 - val_accuracy: 0.4167\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 8s 347ms/step - loss: 1.1801 - accuracy: 0.5830 - val_loss: 1.6335 - val_accuracy: 0.4133\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 8s 344ms/step - loss: 0.8385 - accuracy: 0.7174 - val_loss: 1.7017 - val_accuracy: 0.4400\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 8s 344ms/step - loss: 0.5379 - accuracy: 0.8226 - val_loss: 1.8013 - val_accuracy: 0.4333\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 14s 399ms/step - loss: 2.2355 - accuracy: 0.2559 - val_loss: 1.8898 - val_accuracy: 0.2933\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 8s 359ms/step - loss: 1.6454 - accuracy: 0.4185 - val_loss: 1.8386 - val_accuracy: 0.3433\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 8s 364ms/step - loss: 1.2559 - accuracy: 0.5556 - val_loss: 1.7710 - val_accuracy: 0.3933\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 8s 352ms/step - loss: 0.8105 - accuracy: 0.7333 - val_loss: 2.0249 - val_accuracy: 0.3367\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 8s 354ms/step - loss: 0.4615 - accuracy: 0.8541 - val_loss: 2.1847 - val_accuracy: 0.3800\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 13s 383ms/step - loss: 2.2485 - accuracy: 0.2611 - val_loss: 2.0015 - val_accuracy: 0.3100\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 8s 351ms/step - loss: 1.6786 - accuracy: 0.3985 - val_loss: 1.8885 - val_accuracy: 0.3467\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 8s 353ms/step - loss: 1.2568 - accuracy: 0.5700 - val_loss: 1.8116 - val_accuracy: 0.3833\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 8s 376ms/step - loss: 0.8514 - accuracy: 0.7078 - val_loss: 2.0315 - val_accuracy: 0.3833\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 8s 369ms/step - loss: 0.4989 - accuracy: 0.8322 - val_loss: 2.1268 - val_accuracy: 0.4033\n",
      "mean_score: 0.4023333340883255 ( patch_size 18 )\n",
      "patch_size: 24\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 11s 290ms/step - loss: 2.1702 - accuracy: 0.2456 - val_loss: 1.9349 - val_accuracy: 0.2767\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 6s 262ms/step - loss: 1.6504 - accuracy: 0.4207 - val_loss: 1.8894 - val_accuracy: 0.3233\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 259ms/step - loss: 1.3921 - accuracy: 0.5063 - val_loss: 1.9457 - val_accuracy: 0.3400\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 272ms/step - loss: 1.0712 - accuracy: 0.6222 - val_loss: 2.0271 - val_accuracy: 0.3867\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 6s 267ms/step - loss: 0.7913 - accuracy: 0.7396 - val_loss: 2.2040 - val_accuracy: 0.3400\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 12s 319ms/step - loss: 2.1338 - accuracy: 0.2552 - val_loss: 1.8601 - val_accuracy: 0.3467\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 6s 276ms/step - loss: 1.6568 - accuracy: 0.4107 - val_loss: 1.7321 - val_accuracy: 0.3733\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 269ms/step - loss: 1.3551 - accuracy: 0.5233 - val_loss: 1.6375 - val_accuracy: 0.4333\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 276ms/step - loss: 1.0024 - accuracy: 0.6537 - val_loss: 1.8280 - val_accuracy: 0.4367\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 6s 276ms/step - loss: 0.7020 - accuracy: 0.7511 - val_loss: 2.0715 - val_accuracy: 0.3533\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 12s 320ms/step - loss: 2.2066 - accuracy: 0.2548 - val_loss: 1.8952 - val_accuracy: 0.2600\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 6s 267ms/step - loss: 1.6882 - accuracy: 0.3978 - val_loss: 1.9029 - val_accuracy: 0.2967\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 266ms/step - loss: 1.4738 - accuracy: 0.4700 - val_loss: 1.7517 - val_accuracy: 0.3700\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 278ms/step - loss: 1.1582 - accuracy: 0.5933 - val_loss: 1.8792 - val_accuracy: 0.3567\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 6s 267ms/step - loss: 0.9225 - accuracy: 0.6800 - val_loss: 1.9594 - val_accuracy: 0.3867\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 12s 297ms/step - loss: 2.1638 - accuracy: 0.2578 - val_loss: 1.9611 - val_accuracy: 0.3000\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 6s 268ms/step - loss: 1.6643 - accuracy: 0.4111 - val_loss: 1.7554 - val_accuracy: 0.3567\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 264ms/step - loss: 1.3825 - accuracy: 0.5000 - val_loss: 1.6608 - val_accuracy: 0.4067\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 264ms/step - loss: 1.0753 - accuracy: 0.6230 - val_loss: 1.7067 - val_accuracy: 0.4133\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 6s 267ms/step - loss: 0.7340 - accuracy: 0.7430 - val_loss: 1.9170 - val_accuracy: 0.3967\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 11s 290ms/step - loss: 2.1893 - accuracy: 0.2400 - val_loss: 1.9734 - val_accuracy: 0.3833\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 6s 264ms/step - loss: 1.6724 - accuracy: 0.3944 - val_loss: 1.8294 - val_accuracy: 0.3367\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 260ms/step - loss: 1.3712 - accuracy: 0.5067 - val_loss: 1.7545 - val_accuracy: 0.3833\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 260ms/step - loss: 1.0873 - accuracy: 0.6219 - val_loss: 1.8598 - val_accuracy: 0.4100\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 6s 259ms/step - loss: 0.7802 - accuracy: 0.7289 - val_loss: 2.1509 - val_accuracy: 0.3667\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 12s 318ms/step - loss: 2.2016 - accuracy: 0.2489 - val_loss: 2.0623 - val_accuracy: 0.2700\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 6s 282ms/step - loss: 1.6639 - accuracy: 0.4126 - val_loss: 1.7231 - val_accuracy: 0.3833\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 287ms/step - loss: 1.3750 - accuracy: 0.5011 - val_loss: 1.6777 - val_accuracy: 0.4333\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 289ms/step - loss: 1.0741 - accuracy: 0.6285 - val_loss: 1.9128 - val_accuracy: 0.3833\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 6s 285ms/step - loss: 0.7934 - accuracy: 0.7256 - val_loss: 1.8013 - val_accuracy: 0.4633\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 12s 313ms/step - loss: 2.2265 - accuracy: 0.2504 - val_loss: 2.0103 - val_accuracy: 0.2600\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 6s 282ms/step - loss: 1.6632 - accuracy: 0.4130 - val_loss: 1.8823 - val_accuracy: 0.3067\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 286ms/step - loss: 1.3915 - accuracy: 0.4941 - val_loss: 1.8776 - val_accuracy: 0.3567\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 282ms/step - loss: 1.0743 - accuracy: 0.6222 - val_loss: 1.9640 - val_accuracy: 0.3400\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 6s 285ms/step - loss: 0.7784 - accuracy: 0.7378 - val_loss: 2.3273 - val_accuracy: 0.3400\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 12s 329ms/step - loss: 2.1387 - accuracy: 0.2663 - val_loss: 1.7330 - val_accuracy: 0.3933\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 6s 290ms/step - loss: 1.6388 - accuracy: 0.4056 - val_loss: 1.6231 - val_accuracy: 0.4100\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 284ms/step - loss: 1.2923 - accuracy: 0.5489 - val_loss: 1.6197 - val_accuracy: 0.4600\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 287ms/step - loss: 0.9742 - accuracy: 0.6622 - val_loss: 1.7864 - val_accuracy: 0.4133\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 6s 292ms/step - loss: 0.6475 - accuracy: 0.7833 - val_loss: 1.8613 - val_accuracy: 0.4400\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 12s 332ms/step - loss: 2.1867 - accuracy: 0.2604 - val_loss: 1.9776 - val_accuracy: 0.3033\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 6s 292ms/step - loss: 1.6943 - accuracy: 0.3915 - val_loss: 1.8644 - val_accuracy: 0.3433\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 292ms/step - loss: 1.4166 - accuracy: 0.4926 - val_loss: 1.8185 - val_accuracy: 0.3533\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 288ms/step - loss: 1.0965 - accuracy: 0.6163 - val_loss: 1.9225 - val_accuracy: 0.3833\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 6s 289ms/step - loss: 0.7613 - accuracy: 0.7430 - val_loss: 2.0204 - val_accuracy: 0.3733\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 12s 329ms/step - loss: 2.2001 - accuracy: 0.2515 - val_loss: 1.9895 - val_accuracy: 0.2733\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 7s 301ms/step - loss: 1.6960 - accuracy: 0.3981 - val_loss: 1.7725 - val_accuracy: 0.3867\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 290ms/step - loss: 1.4448 - accuracy: 0.4819 - val_loss: 1.8061 - val_accuracy: 0.3533\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 291ms/step - loss: 1.1322 - accuracy: 0.6019 - val_loss: 1.8676 - val_accuracy: 0.4000\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 7s 300ms/step - loss: 0.8152 - accuracy: 0.7226 - val_loss: 1.9402 - val_accuracy: 0.4300\n",
      "mean_score: 0.38900000154972075 ( patch_size 24 )\n",
      "94/94 [==============================] - 7s 71ms/step - loss: 2.0721 - accuracy: 0.4093\n"
     ]
    }
   ],
   "source": [
    "outer_cv = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "best_params = {}\n",
    "performance_results = []\n",
    "\n",
    "x_combined, y_combined = get_processed_dataset(SMALL)\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size)\n",
    "    ],\n",
    "    name = \"data_augmentation\"\n",
    ")\n",
    "data_augmentation.layers[0].adapt(x_combined)\n",
    "\n",
    "\n",
    "index_k_1 = 0\n",
    "\n",
    "for outer_train_idx, outer_val_idx in outer_cv.split(x_combined):\n",
    "    # print(\"outer_val_idx:\", outer_val_idx)\n",
    "    # print(type(outer_val_idx))\n",
    "    index_k_1 = index_k_1 + 1\n",
    "    print(\"index_k_1\", index_k_1)\n",
    "    \n",
    "    X_outer_train, X_outer_val = x_combined[outer_train_idx], x_combined[outer_val_idx]\n",
    "    y_outer_train, y_outer_val = y_combined[outer_train_idx], y_combined[outer_val_idx]\n",
    "\n",
    "    best_score = -np.inf\n",
    "    best_patch_size = None\n",
    "\n",
    "    for patch_size in patch_size_configs:\n",
    "        print(\"patch_size:\", patch_size)\n",
    "        inner_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        scores = []\n",
    "        \n",
    "        for inner_train_idx, inner_val_idx in inner_cv.split(X_outer_train):\n",
    "            X_inner_train, X_inner_val = X_outer_train[inner_train_idx], X_outer_train[inner_val_idx]\n",
    "            y_inner_train, y_inner_val = y_outer_train[inner_train_idx], y_outer_train[inner_val_idx]\n",
    "            \n",
    "            model = build_ViT_model(patch_size, data_augmentation)\n",
    "            history = model.fit(\n",
    "                x=X_inner_train,\n",
    "                y=y_inner_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=num_epochs,\n",
    "                validation_data=(X_inner_val, y_inner_val)\n",
    "            )\n",
    "            \n",
    "            score = model.evaluate(X_inner_val, y_inner_val, verbose=0)[1] # accuracy\n",
    "            scores.append(score)\n",
    "\n",
    "        mean_score = np.mean(scores)\n",
    "        print(\"mean_score:\", mean_score, \"( patch_size\", patch_size, \")\")\n",
    "        \n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_patch_size = patch_size\n",
    "\n",
    "    best_params[index_k_1] = best_patch_size\n",
    "    final_model = build_ViT_model(best_patch_size, data_augmentation)\n",
    "    final_model.fit(X_outer_train, y_outer_train, epochs=5, batch_size=128, verbose=0)\n",
    "    final_performance = final_model.evaluate(X_outer_val, y_outer_val)[1]\n",
    "    performance_results.append(final_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd42b7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Performance across all outer folds: 0.416333332657814\n",
      "[0.4233333468437195, 0.40933331847190857]\n",
      "Best Parameters for each fold: {1: 12, 2: 18}\n"
     ]
    }
   ],
   "source": [
    "average_performance = np.mean(performance_results)\n",
    "print(f'Average Performance across all outer folds: {average_performance}')\n",
    "print(performance_results)\n",
    "print(f'Best Parameters for each fold: {best_params}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
