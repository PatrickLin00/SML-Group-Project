{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_and_select_best_params(model, X, y, n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    scores = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'roc_auc': []\n",
    "    }\n",
    "\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        history = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test))\n",
    "\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "        y_test = np.argmax(y_test, axis=1) \n",
    "        print(\"y_test: \", y_test)\n",
    "        print(\"y_pred: \", y_pred)\n",
    "        print(\"history: \", history.history)\n",
    "        \n",
    "        scores['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        scores['precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "        scores['recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "        scores['f1'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "        scores['roc_auc'].append(roc_auc_score(y_test, y_pred_prob, multi_class='ovr', average='macro'))  # ROC AUC 多分类问题\n",
    "\n",
    "    avg_scores = {key: np.mean(value) for key, value in scores.items()}\n",
    "    return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100_data(data_dir):\n",
    "    with open(f\"{data_dir}/meta\", 'rb') as f:\n",
    "        meta = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "    with open(f\"{data_dir}/train\", 'rb') as f:\n",
    "        train_data = pickle.load(f, encoding='latin1')\n",
    "        \n",
    "    with open(f\"{data_dir}/test\", 'rb') as f:\n",
    "        test_data = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "    return meta, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cifar100_data(meta, train_data, test_data, need_show_image=False):\n",
    "    # Show Name of Classes\n",
    "    print(\"CIFAR-100 Classes:\")\n",
    "    for i, label in enumerate(meta['fine_label_names']):\n",
    "        print(f\"{i}: {label}\")\n",
    "    \n",
    "    # Show Training data shape and num\n",
    "    print(f\"\\nTrain data shape: {train_data['data'].shape}\")\n",
    "    print(f\"Number of training examples: {train_data['data'].shape[0]}\")\n",
    "    \n",
    "    # Show Testing data shape and num\n",
    "    print(f\"\\nTest data shape: {test_data['data'].shape}\")\n",
    "    print(f\"Number of test examples: {test_data['data'].shape[0]}\")\n",
    "\n",
    "    # Show some images from training set if need\n",
    "    if need_show_image:\n",
    "        num_images = 10  # num to show\n",
    "        images = train_data['data'][:num_images]\n",
    "        labels = train_data['fine_labels'][:num_images]\n",
    "    \n",
    "        images = images.reshape(num_images, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "        images = np.clip(images / 255.0, 0, 1)  \n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i in range(num_images):\n",
    "            plt.subplot(2, 5, i + 1)\n",
    "            plt.imshow(images[i])\n",
    "            plt.title(meta['fine_label_names'][labels[i]])\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-100 Classes:\n",
      "0: apple\n",
      "1: aquarium_fish\n",
      "2: baby\n",
      "3: bear\n",
      "4: beaver\n",
      "5: bed\n",
      "6: bee\n",
      "7: beetle\n",
      "8: bicycle\n",
      "9: bottle\n",
      "10: bowl\n",
      "11: boy\n",
      "12: bridge\n",
      "13: bus\n",
      "14: butterfly\n",
      "15: camel\n",
      "16: can\n",
      "17: castle\n",
      "18: caterpillar\n",
      "19: cattle\n",
      "20: chair\n",
      "21: chimpanzee\n",
      "22: clock\n",
      "23: cloud\n",
      "24: cockroach\n",
      "25: couch\n",
      "26: crab\n",
      "27: crocodile\n",
      "28: cup\n",
      "29: dinosaur\n",
      "30: dolphin\n",
      "31: elephant\n",
      "32: flatfish\n",
      "33: forest\n",
      "34: fox\n",
      "35: girl\n",
      "36: hamster\n",
      "37: house\n",
      "38: kangaroo\n",
      "39: keyboard\n",
      "40: lamp\n",
      "41: lawn_mower\n",
      "42: leopard\n",
      "43: lion\n",
      "44: lizard\n",
      "45: lobster\n",
      "46: man\n",
      "47: maple_tree\n",
      "48: motorcycle\n",
      "49: mountain\n",
      "50: mouse\n",
      "51: mushroom\n",
      "52: oak_tree\n",
      "53: orange\n",
      "54: orchid\n",
      "55: otter\n",
      "56: palm_tree\n",
      "57: pear\n",
      "58: pickup_truck\n",
      "59: pine_tree\n",
      "60: plain\n",
      "61: plate\n",
      "62: poppy\n",
      "63: porcupine\n",
      "64: possum\n",
      "65: rabbit\n",
      "66: raccoon\n",
      "67: ray\n",
      "68: road\n",
      "69: rocket\n",
      "70: rose\n",
      "71: sea\n",
      "72: seal\n",
      "73: shark\n",
      "74: shrew\n",
      "75: skunk\n",
      "76: skyscraper\n",
      "77: snail\n",
      "78: snake\n",
      "79: spider\n",
      "80: squirrel\n",
      "81: streetcar\n",
      "82: sunflower\n",
      "83: sweet_pepper\n",
      "84: table\n",
      "85: tank\n",
      "86: telephone\n",
      "87: television\n",
      "88: tiger\n",
      "89: tractor\n",
      "90: train\n",
      "91: trout\n",
      "92: tulip\n",
      "93: turtle\n",
      "94: wardrobe\n",
      "95: whale\n",
      "96: willow_tree\n",
      "97: wolf\n",
      "98: woman\n",
      "99: worm\n",
      "\n",
      "Train data shape: (50000, 3072)\n",
      "Number of training examples: 50000\n",
      "\n",
      "Test data shape: (10000, 3072)\n",
      "Number of test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'cifar-100-python'  # path directory\n",
    "meta, train_data, test_data = load_cifar100_data(data_dir)\n",
    "display_cifar100_data(meta, train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_train_test_data(train_data, test_data):\n",
    "    X_train = train_data['data']\n",
    "    y_train = train_data['fine_labels']\n",
    "    \n",
    "    X_test = test_data['data']\n",
    "    y_test = test_data['fine_labels']\n",
    "    \n",
    "    X_combined = np.concatenate((X_train, X_test), axis=0)\n",
    "    y_combined = np.concatenate((y_train, y_test), axis=0)\n",
    "    \n",
    "    return X_combined, y_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_3d_cnn(input_shape, num_classes, learning_rate=0.0005, num_filter=16, filter_size=(3,3,3), dropout_rate=0.5):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv3D(num_filter, filter_size, activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.MaxPooling3D((1, 2, 2))) \n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_4\" is incompatible with the layer: expected axis -1 of input shape to have value 20480, but received input with shape (128, 2048)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(128, 1, 32, 32, 3), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m y_combined \u001b[38;5;241m=\u001b[39m to_categorical(y_combined, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     21\u001b[0m X_combined_reshaped \u001b[38;5;241m=\u001b[39m X_combined_reshaped\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m---> 23\u001b[0m avg_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_and_select_best_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_combined_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_config: \u001b[39m\u001b[38;5;124m\"\u001b[39m, current_config)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(avg_scores)\n",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m, in \u001b[0;36mcross_validate_and_select_best_params\u001b[1;34m(model, X, y, n_splits)\u001b[0m\n\u001b[0;32m     13\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m X[train_index], X[test_index]\n\u001b[0;32m     14\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y[train_index], y[test_index]\n\u001b[1;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred_prob, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Deyu0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Deyu0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_4\" is incompatible with the layer: expected axis -1 of input shape to have value 20480, but received input with shape (128, 2048)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(128, 1, 32, 32, 3), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "input_shape = (1, 32, 32, 3)\n",
    "num_classes = 100\n",
    "\n",
    "learning_rates=[0.001, 0.0005, 0.0015, 0.01, 0.005]\n",
    "num_filters=[8, 16, 32, 64, 128]\n",
    "filter_sizes=[(1,1,1), (3,3,3), (5,5,5), (7,7,7), (9,9,9)]\n",
    "dropout_rates=[0.3, 0.5, 0.6, 0.75, 0.9]\n",
    "\n",
    "highest_config=[]\n",
    "highest_accuracy=0\n",
    "for learning_rate in learning_rates:\n",
    "    for num_filter in num_filters:\n",
    "        for filter_size in filter_sizes:\n",
    "            for dropout_rate in dropout_rates:\n",
    "                current_config = [learning_rate, num_filter, filter_size, dropout_rate]\n",
    "                model = build_simple_3d_cnn(input_shape, num_classes, learning_rate, num_filter, filter_size, dropout_rate)\n",
    "\n",
    "                X_combined, y_combined = merge_train_test_data(train_data, test_data)\n",
    "                X_combined_reshaped = X_combined.reshape(-1, 1, 32, 32, 3)\n",
    "                y_combined = to_categorical(y_combined, num_classes=100)\n",
    "                X_combined_reshaped = X_combined_reshaped.astype('float32') / 255.0\n",
    "\n",
    "                avg_scores = cross_validate_and_select_best_params(model, X_combined_reshaped, y_combined)\n",
    "                print(\"current_config: \", current_config)\n",
    "                print(avg_scores)\n",
    "\n",
    "                if avg_scores['accuracy'] > highest_accuracy:\n",
    "                    highest_config = current_config\n",
    "                    highest_accuracy = avg_scores['accuracy']\n",
    "                    print(\"highest_config: \", highest_config)\n",
    "                    print(\"highest_accuracy: \", highest_accuracy)\n",
    "\n",
    "print(\"highest_config: \", highest_config)\n",
    "print(\"highest_accuracy: \", highest_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.4035166666666667, 'precision': 0.40174463535938365, 'recall': 0.40408168734279226, 'f1': 0.3942659829732732, 'roc_auc': 0.9404188626066154}\n"
     ]
    }
   ],
   "source": [
    "print(avg_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
