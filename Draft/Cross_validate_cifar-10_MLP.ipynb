{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc1c906-f0f6-4e09-9494-b43ab0d073a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c46196e-7676-499b-8538-9154b34c5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess data\n",
    "def load_cifar10_data(data_dir):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(1, 6):\n",
    "        with open(os.path.join(data_dir, f'data_batch_{i}'), 'rb') as file:\n",
    "            batch = pickle.load(file, encoding='latin1')\n",
    "            X.append(batch['data'])\n",
    "            Y.extend(batch['labels'])\n",
    "    X = np.concatenate(X).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "    X_test, Y_test = None, None\n",
    "    with open(os.path.join(data_dir, 'test_batch'), 'rb') as file:\n",
    "        test_batch = pickle.load(file, encoding='latin1')\n",
    "        X_test = test_batch['data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "        Y_test = test_batch['labels']\n",
    "    X = np.vstack((X, X_test))\n",
    "    Y.extend(Y_test)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6bed1e-e68d-473b-b683-06bc2b0a6f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the MLP model\n",
    "def build_mlp_model(input_shape, num_classes, learning_rate, num_units, dropout_rate):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(num_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e37563-206b-4169-a1ea-17e2a1effd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define cross-validation function\n",
    "def cross_validate_and_select_best_params(model, X, y, n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train, epochs=5, batch_size=128, verbose=0)\n",
    "        scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "        accuracies.append(scores[1])\n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c0e5908-51bc-4048-a95f-04496871b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 data\n",
    "data_dir = 'cifar-10-batches-py'\n",
    "X_combined, y_combined = load_cifar10_data(data_dir)\n",
    "X_combined = X_combined.astype('float32') / 255.0\n",
    "y_combined = to_categorical(y_combined, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee6c9ea-93cb-41cc-a3e7-41207fd89eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: LR=0.001, Units=8, Dropout=0 | Accuracy=0.0954\n",
      "New highest found: [0.001, 8, 0] with accuracy: 0.09543333202600479\n",
      "Config: LR=0.001, Units=8, Dropout=0.1 | Accuracy=0.0956\n",
      "New highest found: [0.001, 8, 0.1] with accuracy: 0.09563333243131637\n",
      "Config: LR=0.001, Units=8, Dropout=0.3 | Accuracy=0.0956\n",
      "Config: LR=0.001, Units=8, Dropout=0.5 | Accuracy=0.0953\n",
      "Config: LR=0.001, Units=8, Dropout=0.75 | Accuracy=0.0953\n",
      "Config: LR=0.001, Units=16, Dropout=0 | Accuracy=0.3698\n",
      "New highest found: [0.001, 16, 0] with accuracy: 0.36978332996368407\n",
      "Config: LR=0.001, Units=16, Dropout=0.1 | Accuracy=0.3237\n",
      "Config: LR=0.001, Units=16, Dropout=0.3 | Accuracy=0.1869\n",
      "Config: LR=0.001, Units=16, Dropout=0.5 | Accuracy=0.0953\n",
      "Config: LR=0.001, Units=16, Dropout=0.75 | Accuracy=0.0959\n",
      "Config: LR=0.001, Units=32, Dropout=0 | Accuracy=0.3720\n",
      "New highest found: [0.001, 32, 0] with accuracy: 0.3720333337783813\n",
      "Config: LR=0.001, Units=32, Dropout=0.1 | Accuracy=0.3051\n",
      "Config: LR=0.001, Units=32, Dropout=0.3 | Accuracy=0.2030\n",
      "Config: LR=0.001, Units=32, Dropout=0.5 | Accuracy=0.0954\n",
      "Config: LR=0.001, Units=32, Dropout=0.75 | Accuracy=0.0953\n",
      "Config: LR=0.001, Units=64, Dropout=0 | Accuracy=0.4570\n",
      "New highest found: [0.001, 64, 0] with accuracy: 0.45698333978652955\n",
      "Config: LR=0.001, Units=64, Dropout=0.1 | Accuracy=0.4167\n",
      "Config: LR=0.001, Units=64, Dropout=0.3 | Accuracy=0.1850\n",
      "Config: LR=0.001, Units=64, Dropout=0.5 | Accuracy=0.1767\n",
      "Config: LR=0.001, Units=64, Dropout=0.75 | Accuracy=0.0966\n",
      "Config: LR=0.001, Units=128, Dropout=0 | Accuracy=0.4968\n",
      "New highest found: [0.001, 128, 0] with accuracy: 0.49678332805633546\n",
      "Config: LR=0.001, Units=128, Dropout=0.1 | Accuracy=0.4504\n",
      "Config: LR=0.001, Units=128, Dropout=0.3 | Accuracy=0.3458\n",
      "Config: LR=0.001, Units=128, Dropout=0.5 | Accuracy=0.1870\n",
      "Config: LR=0.001, Units=128, Dropout=0.75 | Accuracy=0.0959\n",
      "Config: LR=0.0005, Units=8, Dropout=0 | Accuracy=0.3674\n",
      "Config: LR=0.0005, Units=8, Dropout=0.1 | Accuracy=0.1853\n",
      "Config: LR=0.0005, Units=8, Dropout=0.3 | Accuracy=0.2270\n",
      "Config: LR=0.0005, Units=8, Dropout=0.5 | Accuracy=0.0951\n",
      "Config: LR=0.0005, Units=8, Dropout=0.75 | Accuracy=0.0953\n",
      "Config: LR=0.0005, Units=16, Dropout=0 | Accuracy=0.1931\n",
      "Config: LR=0.0005, Units=16, Dropout=0.1 | Accuracy=0.3054\n",
      "Config: LR=0.0005, Units=16, Dropout=0.3 | Accuracy=0.1870\n",
      "Config: LR=0.0005, Units=16, Dropout=0.5 | Accuracy=0.1714\n",
      "Config: LR=0.0005, Units=16, Dropout=0.75 | Accuracy=0.0951\n",
      "Config: LR=0.0005, Units=32, Dropout=0 | Accuracy=0.4041\n",
      "Config: LR=0.0005, Units=32, Dropout=0.1 | Accuracy=0.4155\n",
      "Config: LR=0.0005, Units=32, Dropout=0.3 | Accuracy=0.3219\n",
      "Config: LR=0.0005, Units=32, Dropout=0.5 | Accuracy=0.0951\n",
      "Config: LR=0.0005, Units=32, Dropout=0.75 | Accuracy=0.0954\n",
      "Config: LR=0.0005, Units=64, Dropout=0 | Accuracy=0.4764\n",
      "Config: LR=0.0005, Units=64, Dropout=0.1 | Accuracy=0.4355\n",
      "Config: LR=0.0005, Units=64, Dropout=0.3 | Accuracy=0.3105\n",
      "Config: LR=0.0005, Units=64, Dropout=0.5 | Accuracy=0.2380\n",
      "Config: LR=0.0005, Units=64, Dropout=0.75 | Accuracy=0.0953\n",
      "Config: LR=0.0005, Units=128, Dropout=0 | Accuracy=0.4974\n",
      "New highest found: [0.0005, 128, 0] with accuracy: 0.4974166572093964\n",
      "Config: LR=0.0005, Units=128, Dropout=0.1 | Accuracy=0.4835\n",
      "Config: LR=0.0005, Units=128, Dropout=0.3 | Accuracy=0.4211\n",
      "Config: LR=0.0005, Units=128, Dropout=0.5 | Accuracy=0.2760\n",
      "Config: LR=0.0005, Units=128, Dropout=0.75 | Accuracy=0.0951\n",
      "Config: LR=0.0015, Units=8, Dropout=0 | Accuracy=0.3374\n",
      "Config: LR=0.0015, Units=8, Dropout=0.1 | Accuracy=0.0962\n",
      "Config: LR=0.0015, Units=8, Dropout=0.3 | Accuracy=0.0953\n",
      "Config: LR=0.0015, Units=8, Dropout=0.5 | Accuracy=0.0962\n",
      "Config: LR=0.0015, Units=8, Dropout=0.75 | Accuracy=0.0969\n",
      "Config: LR=0.0015, Units=16, Dropout=0 | Accuracy=0.1971\n",
      "Config: LR=0.0015, Units=16, Dropout=0.1 | Accuracy=0.0954\n",
      "Config: LR=0.0015, Units=16, Dropout=0.3 | Accuracy=0.0964\n",
      "Config: LR=0.0015, Units=16, Dropout=0.5 | Accuracy=0.0956\n",
      "Config: LR=0.0015, Units=16, Dropout=0.75 | Accuracy=0.0980\n",
      "Config: LR=0.0015, Units=32, Dropout=0 | Accuracy=0.1891\n",
      "Config: LR=0.0015, Units=32, Dropout=0.1 | Accuracy=0.1937\n",
      "Config: LR=0.0015, Units=32, Dropout=0.3 | Accuracy=0.1876\n",
      "Config: LR=0.0015, Units=32, Dropout=0.5 | Accuracy=0.0953\n",
      "Config: LR=0.0015, Units=32, Dropout=0.75 | Accuracy=0.0960\n",
      "Config: LR=0.0015, Units=64, Dropout=0 | Accuracy=0.4461\n",
      "Config: LR=0.0015, Units=64, Dropout=0.1 | Accuracy=0.3803\n",
      "Config: LR=0.0015, Units=64, Dropout=0.3 | Accuracy=0.2314\n",
      "Config: LR=0.0015, Units=64, Dropout=0.5 | Accuracy=0.0952\n",
      "Config: LR=0.0015, Units=64, Dropout=0.75 | Accuracy=0.0961\n",
      "Config: LR=0.0015, Units=128, Dropout=0 | Accuracy=0.4903\n",
      "Config: LR=0.0015, Units=128, Dropout=0.1 | Accuracy=0.4097\n",
      "Config: LR=0.0015, Units=128, Dropout=0.3 | Accuracy=0.3243\n",
      "Config: LR=0.0015, Units=128, Dropout=0.5 | Accuracy=0.0962\n",
      "Config: LR=0.0015, Units=128, Dropout=0.75 | Accuracy=0.0957\n",
      "Config: LR=0.01, Units=8, Dropout=0 | Accuracy=0.0976\n",
      "Config: LR=0.01, Units=8, Dropout=0.1 | Accuracy=0.1822\n",
      "Config: LR=0.01, Units=8, Dropout=0.3 | Accuracy=0.0984\n",
      "Config: LR=0.01, Units=8, Dropout=0.5 | Accuracy=0.0991\n",
      "Config: LR=0.01, Units=8, Dropout=0.75 | Accuracy=0.0968\n",
      "Config: LR=0.01, Units=16, Dropout=0 | Accuracy=0.0973\n",
      "Config: LR=0.01, Units=16, Dropout=0.1 | Accuracy=0.0986\n",
      "Config: LR=0.01, Units=16, Dropout=0.3 | Accuracy=0.0992\n",
      "Config: LR=0.01, Units=16, Dropout=0.5 | Accuracy=0.0983\n",
      "Config: LR=0.01, Units=16, Dropout=0.75 | Accuracy=0.1009\n",
      "Config: LR=0.01, Units=32, Dropout=0 | Accuracy=0.0994\n",
      "Config: LR=0.01, Units=32, Dropout=0.1 | Accuracy=0.2720\n",
      "Config: LR=0.01, Units=32, Dropout=0.3 | Accuracy=0.1009\n",
      "Config: LR=0.01, Units=32, Dropout=0.5 | Accuracy=0.0995\n",
      "Config: LR=0.01, Units=32, Dropout=0.75 | Accuracy=0.0985\n",
      "Config: LR=0.01, Units=64, Dropout=0 | Accuracy=0.3002\n",
      "Config: LR=0.01, Units=64, Dropout=0.1 | Accuracy=0.3260\n",
      "Config: LR=0.01, Units=64, Dropout=0.3 | Accuracy=0.0987\n",
      "Config: LR=0.01, Units=64, Dropout=0.5 | Accuracy=0.0976\n",
      "Config: LR=0.01, Units=64, Dropout=0.75 | Accuracy=0.0987\n",
      "Config: LR=0.01, Units=128, Dropout=0 | Accuracy=0.3183\n",
      "Config: LR=0.01, Units=128, Dropout=0.1 | Accuracy=0.2550\n",
      "Config: LR=0.01, Units=128, Dropout=0.3 | Accuracy=0.1671\n",
      "Config: LR=0.01, Units=128, Dropout=0.5 | Accuracy=0.0984\n",
      "Config: LR=0.01, Units=128, Dropout=0.75 | Accuracy=0.0988\n",
      "Config: LR=0.005, Units=8, Dropout=0 | Accuracy=0.1016\n",
      "Config: LR=0.005, Units=8, Dropout=0.1 | Accuracy=0.1868\n",
      "Config: LR=0.005, Units=8, Dropout=0.3 | Accuracy=0.1003\n",
      "Config: LR=0.005, Units=8, Dropout=0.5 | Accuracy=0.0979\n",
      "Config: LR=0.005, Units=8, Dropout=0.75 | Accuracy=0.0973\n",
      "Config: LR=0.005, Units=16, Dropout=0 | Accuracy=0.1003\n",
      "Config: LR=0.005, Units=16, Dropout=0.1 | Accuracy=0.0986\n",
      "Config: LR=0.005, Units=16, Dropout=0.3 | Accuracy=0.1002\n",
      "Config: LR=0.005, Units=16, Dropout=0.5 | Accuracy=0.0994\n",
      "Config: LR=0.005, Units=16, Dropout=0.75 | Accuracy=0.0996\n",
      "Config: LR=0.005, Units=32, Dropout=0 | Accuracy=0.4049\n",
      "Config: LR=0.005, Units=32, Dropout=0.1 | Accuracy=0.2426\n",
      "Config: LR=0.005, Units=32, Dropout=0.3 | Accuracy=0.0973\n",
      "Config: LR=0.005, Units=32, Dropout=0.5 | Accuracy=0.1013\n",
      "Config: LR=0.005, Units=32, Dropout=0.75 | Accuracy=0.0963\n",
      "Config: LR=0.005, Units=64, Dropout=0 | Accuracy=0.4285\n",
      "Config: LR=0.005, Units=64, Dropout=0.1 | Accuracy=0.2669\n",
      "Config: LR=0.005, Units=64, Dropout=0.3 | Accuracy=0.1809\n",
      "Config: LR=0.005, Units=64, Dropout=0.5 | Accuracy=0.0997\n",
      "Config: LR=0.005, Units=64, Dropout=0.75 | Accuracy=0.0977\n",
      "Config: LR=0.005, Units=128, Dropout=0 | Accuracy=0.4308\n",
      "Config: LR=0.005, Units=128, Dropout=0.1 | Accuracy=0.2435\n",
      "Config: LR=0.005, Units=128, Dropout=0.3 | Accuracy=0.1773\n",
      "Config: LR=0.005, Units=128, Dropout=0.5 | Accuracy=0.0988\n",
      "Config: LR=0.005, Units=128, Dropout=0.75 | Accuracy=0.0988\n",
      "Highest configuration: [0.0005, 128, 0]\n",
      "Highest accuracy: 0.4974166572093964\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Iterate over parameter combinations\n",
    "learning_rates = [0.001, 0.0005, 0.0015, 0.01, 0.005]\n",
    "unit_sizes = [8, 16, 32,64, 128]\n",
    "dropout_rates = [0, 0.1, 0.3, 0.5, 0.75]\n",
    "highest_accuracy = 0\n",
    "highest_config = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for num_units in unit_sizes:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = build_mlp_model((32, 32, 3), 10, learning_rate, num_units, dropout_rate)\n",
    "            avg_accuracy = cross_validate_and_select_best_params(model, X_combined, y_combined)\n",
    "            print(f\"Config: LR={learning_rate}, Units={num_units}, Dropout={dropout_rate} | Accuracy={avg_accuracy:.4f}\")\n",
    "            if avg_accuracy > highest_accuracy:\n",
    "                highest_accuracy = avg_accuracy\n",
    "                highest_config = [learning_rate, num_units, dropout_rate]\n",
    "                print(\"New highest found:\", highest_config, \"with accuracy:\", highest_accuracy)\n",
    "\n",
    "print(\"Highest configuration:\", highest_config)\n",
    "print(\"Highest accuracy:\", highest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f601f7f-d266-4783-b43f-063abc8ff5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: LR=0.001, Units=256, Dropout=0 | Accuracy=0.5147\n",
      "New highest found: [0.001, 256, 0] with accuracy: 0.514683336019516\n",
      "Config: LR=0.001, Units=256, Dropout=0.1 | Accuracy=0.4824\n",
      "Config: LR=0.001, Units=256, Dropout=0.3 | Accuracy=0.4097\n",
      "Config: LR=0.001, Units=256, Dropout=0.5 | Accuracy=0.2617\n",
      "Config: LR=0.001, Units=256, Dropout=0.75 | Accuracy=0.0978\n",
      "Config: LR=0.001, Units=512, Dropout=0 | Accuracy=0.5284\n",
      "New highest found: [0.001, 512, 0] with accuracy: 0.5284333229064941\n",
      "Config: LR=0.001, Units=512, Dropout=0.1 | Accuracy=0.4959\n",
      "Config: LR=0.001, Units=512, Dropout=0.3 | Accuracy=0.4297\n",
      "Config: LR=0.001, Units=512, Dropout=0.5 | Accuracy=0.3306\n",
      "Config: LR=0.001, Units=512, Dropout=0.75 | Accuracy=0.0966\n",
      "Config: LR=0.0005, Units=256, Dropout=0 | Accuracy=0.5260\n",
      "Config: LR=0.0005, Units=256, Dropout=0.1 | Accuracy=0.5065\n",
      "Config: LR=0.0005, Units=256, Dropout=0.3 | Accuracy=0.4452\n",
      "Config: LR=0.0005, Units=256, Dropout=0.5 | Accuracy=0.3339\n",
      "Config: LR=0.0005, Units=256, Dropout=0.75 | Accuracy=0.0955\n",
      "Config: LR=0.0005, Units=512, Dropout=0 | Accuracy=0.5472\n",
      "New highest found: [0.0005, 512, 0] with accuracy: 0.5471666634082795\n",
      "Config: LR=0.0005, Units=512, Dropout=0.1 | Accuracy=0.5282\n",
      "Config: LR=0.0005, Units=512, Dropout=0.3 | Accuracy=0.4682\n",
      "Config: LR=0.0005, Units=512, Dropout=0.5 | Accuracy=0.3996\n",
      "Config: LR=0.0005, Units=512, Dropout=0.75 | Accuracy=0.1702\n",
      "Config: LR=0.0015, Units=256, Dropout=0 | Accuracy=0.5024\n",
      "Config: LR=0.0015, Units=256, Dropout=0.1 | Accuracy=0.4634\n",
      "Config: LR=0.0015, Units=256, Dropout=0.3 | Accuracy=0.3699\n",
      "Config: LR=0.0015, Units=256, Dropout=0.5 | Accuracy=0.2185\n",
      "Config: LR=0.0015, Units=256, Dropout=0.75 | Accuracy=0.0970\n",
      "Config: LR=0.0015, Units=512, Dropout=0 | Accuracy=0.5135\n",
      "Config: LR=0.0015, Units=512, Dropout=0.1 | Accuracy=0.4681\n",
      "Config: LR=0.0015, Units=512, Dropout=0.3 | Accuracy=0.3933\n",
      "Config: LR=0.0015, Units=512, Dropout=0.5 | Accuracy=0.2904\n",
      "Config: LR=0.0015, Units=512, Dropout=0.75 | Accuracy=0.0969\n",
      "Config: LR=0.01, Units=256, Dropout=0 | Accuracy=0.1949\n",
      "Config: LR=0.01, Units=256, Dropout=0.1 | Accuracy=0.2518\n",
      "Config: LR=0.01, Units=256, Dropout=0.3 | Accuracy=0.0996\n",
      "Config: LR=0.01, Units=256, Dropout=0.5 | Accuracy=0.0987\n",
      "Config: LR=0.01, Units=256, Dropout=0.75 | Accuracy=0.0971\n",
      "Config: LR=0.01, Units=512, Dropout=0 | Accuracy=0.0972\n",
      "Config: LR=0.01, Units=512, Dropout=0.1 | Accuracy=0.0980\n",
      "Config: LR=0.01, Units=512, Dropout=0.3 | Accuracy=0.1006\n",
      "Config: LR=0.01, Units=512, Dropout=0.5 | Accuracy=0.1006\n",
      "Config: LR=0.01, Units=512, Dropout=0.75 | Accuracy=0.0971\n",
      "Config: LR=0.005, Units=256, Dropout=0 | Accuracy=0.4318\n",
      "Config: LR=0.005, Units=256, Dropout=0.1 | Accuracy=0.3195\n",
      "Config: LR=0.005, Units=256, Dropout=0.3 | Accuracy=0.1006\n",
      "Config: LR=0.005, Units=256, Dropout=0.5 | Accuracy=0.1721\n",
      "Config: LR=0.005, Units=256, Dropout=0.75 | Accuracy=0.0991\n",
      "Config: LR=0.005, Units=512, Dropout=0 | Accuracy=0.4050\n",
      "Config: LR=0.005, Units=512, Dropout=0.1 | Accuracy=0.2527\n",
      "Config: LR=0.005, Units=512, Dropout=0.3 | Accuracy=0.2404\n",
      "Config: LR=0.005, Units=512, Dropout=0.5 | Accuracy=0.1720\n",
      "Config: LR=0.005, Units=512, Dropout=0.75 | Accuracy=0.0999\n",
      "Highest configuration: [0.0005, 512, 0]\n",
      "Highest accuracy: 0.5471666634082795\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Iterate over parameter combinations\n",
    "learning_rates = [0.001, 0.0005, 0.0015, 0.01, 0.005]\n",
    "unit_sizes = [256, 512]\n",
    "dropout_rates = [0, 0.1, 0.3, 0.5, 0.75]\n",
    "highest_accuracy = 0\n",
    "highest_config = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for num_units in unit_sizes:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = build_mlp_model((32, 32, 3), 10, learning_rate, num_units, dropout_rate)\n",
    "            avg_accuracy = cross_validate_and_select_best_params(model, X_combined, y_combined)\n",
    "            print(f\"Config: LR={learning_rate}, Units={num_units}, Dropout={dropout_rate} | Accuracy={avg_accuracy:.4f}\")\n",
    "            if avg_accuracy > highest_accuracy:\n",
    "                highest_accuracy = avg_accuracy\n",
    "                highest_config = [learning_rate, num_units, dropout_rate]\n",
    "                print(\"New highest found:\", highest_config, \"with accuracy:\", highest_accuracy)\n",
    "\n",
    "print(\"Highest configuration:\", highest_config)\n",
    "print(\"Highest accuracy:\", highest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3038103f-70e4-4dce-9de4-a789467ad4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: LR=0.0005, Units=1024, Dropout=0 | Accuracy=0.5608\n",
      "New highest found: [0.0005, 1024, 0] with accuracy: 0.560783326625824\n",
      "Highest configuration: [0.0005, 1024, 0]\n",
      "Highest accuracy: 0.560783326625824\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Iterate over parameter combinations\n",
    "learning_rates = [0.0005]\n",
    "unit_sizes = [1024]\n",
    "dropout_rates = [0]\n",
    "highest_accuracy = 0\n",
    "highest_config = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for num_units in unit_sizes:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = build_mlp_model((32, 32, 3), 10, learning_rate, num_units, dropout_rate)\n",
    "            avg_accuracy = cross_validate_and_select_best_params(model, X_combined, y_combined)\n",
    "            print(f\"Config: LR={learning_rate}, Units={num_units}, Dropout={dropout_rate} | Accuracy={avg_accuracy:.4f}\")\n",
    "            if avg_accuracy > highest_accuracy:\n",
    "                highest_accuracy = avg_accuracy\n",
    "                highest_config = [learning_rate, num_units, dropout_rate]\n",
    "                print(\"New highest found:\", highest_config, \"with accuracy:\", highest_accuracy)\n",
    "\n",
    "print(\"Highest configuration:\", highest_config)\n",
    "print(\"Highest accuracy:\", highest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6debdb3f-5aa7-482e-a1fc-2f84bd5a6139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: LR=0.0005, Units=2048, Dropout=0 | Accuracy=0.5691\n",
      "New highest found: [0.0005, 2048, 0] with accuracy: 0.5690999984741211\n",
      "Highest configuration: [0.0005, 2048, 0]\n",
      "Highest accuracy: 0.5690999984741211\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Iterate over parameter combinations\n",
    "learning_rates = [0.0005]\n",
    "unit_sizes = [2048]\n",
    "dropout_rates = [0]\n",
    "highest_accuracy = 0\n",
    "highest_config = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for num_units in unit_sizes:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = build_mlp_model((32, 32, 3), 10, learning_rate, num_units, dropout_rate)\n",
    "            avg_accuracy = cross_validate_and_select_best_params(model, X_combined, y_combined)\n",
    "            print(f\"Config: LR={learning_rate}, Units={num_units}, Dropout={dropout_rate} | Accuracy={avg_accuracy:.4f}\")\n",
    "            if avg_accuracy > highest_accuracy:\n",
    "                highest_accuracy = avg_accuracy\n",
    "                highest_config = [learning_rate, num_units, dropout_rate]\n",
    "                print(\"New highest found:\", highest_config, \"with accuracy:\", highest_accuracy)\n",
    "\n",
    "print(\"Highest configuration:\", highest_config)\n",
    "print(\"Highest accuracy:\", highest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ddfafb4-e388-44ac-93ae-d78ab96ea2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define cross-validation function\n",
    "def cross_validate_and_select_best_params(model, X, y, n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=0)\n",
    "        scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "        accuracies.append(scores[1])\n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55d5d159-9d57-43ee-8840-e9e80bd5fff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: LR=0.0005, Units=2048, Dropout=0 | Accuracy=0.6490\n",
      "New highest found: [0.0005, 2048, 0] with accuracy: 0.6490333437919616\n",
      "Highest configuration: [0.0005, 2048, 0]\n",
      "Highest accuracy: 0.6490333437919616\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Iterate over parameter combinations\n",
    "learning_rates = [0.0005]\n",
    "unit_sizes = [2048]\n",
    "dropout_rates = [0]\n",
    "highest_accuracy = 0\n",
    "highest_config = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for num_units in unit_sizes:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = build_mlp_model((32, 32, 3), 10, learning_rate, num_units, dropout_rate)\n",
    "            avg_accuracy = cross_validate_and_select_best_params(model, X_combined, y_combined)\n",
    "            print(f\"Config: LR={learning_rate}, Units={num_units}, Dropout={dropout_rate} | Accuracy={avg_accuracy:.4f}\")\n",
    "            if avg_accuracy > highest_accuracy:\n",
    "                highest_accuracy = avg_accuracy\n",
    "                highest_config = [learning_rate, num_units, dropout_rate]\n",
    "                print(\"New highest found:\", highest_config, \"with accuracy:\", highest_accuracy)\n",
    "\n",
    "print(\"Highest configuration:\", highest_config)\n",
    "print(\"Highest accuracy:\", highest_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
